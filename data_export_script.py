# å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# !pip install requests pandas
import datetime
import time

# èªè¨¼æƒ…å ±ã¨Supabaseè¨­å®š
SUPABASE_URL = "https://sooyxifnzwyfkrkqpafb.supabase.co"
EMAIL = "csv_user@example.com"
PASSWORD = "uD!WiC92*DR$fy6"

# FLUX.1 APIè¨­å®š
REPLICATE_API_TOKEN = "dc_fa920707481072ba99eb280e2f3bd246f04be4e8ffce4c19b45c012fef9964b4149809b3d0ecacdf700de0d5332d25ac975a2851cfd1e23358f0be116c0d284e84e94efe35c30a9beb77f418f29b642917729872c48e05c4f5e65ae01ec4491948186e2bcbc8d1b58048c8086b24b6c4929ae5d9bd5a4e962cd13cbfafcd59f7"

# èªè¨¼ã—ã¦access_tokenã‚’å–å¾—
import requests
import pandas as pd

auth_url = f"{SUPABASE_URL}/auth/v1/token?grant_type=password"
headers = {
    "Content-Type": "application/json",
    "apikey": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNvb3l4aWZuend5Zmtya3FwYWZiIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTA5NTE3ODksImV4cCI6MjA2NjUyNzc4OX0.XKWHajV9agHwQv3xz1gL4P4IUtwES5uFykAV06CUb1s"
}

payload = {
    "email": EMAIL,
    "password": PASSWORD
}

try:
    auth_response = requests.post(auth_url, headers=headers, json=payload)
    auth_response.raise_for_status()
    access_token = auth_response.json()["access_token"]
    print("âœ… èªè¨¼æˆåŠŸ")
except Exception as e:
    print(f"âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
    exit()

# REST APIçµŒç”±ã§prediction_logsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
data_url = f"{SUPABASE_URL}/rest/v1/prediction_logs"
data_headers = {
    "Authorization": f"Bearer {access_token}",
    "apikey": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNvb3l4aWZuend5Zmtya3FwYWZiIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTA5NTE3ODksImV4cCI6MjA2NjUyNzc4OX0.XKWHajV9agHwQv3xz1gL4P4IUtwES5uFykAV06CUb1s",
    "Content-Type": "application/json"
}

# å¿…è¦ãªåˆ—ã®ã¿ã‚’é¸æŠ
params = {
    "select": "id,prediction_started_at,prediction_completed_at,line_user_id,display_name,purchase_source,has_purchase_experience,breed,gender,birth_date,current_weight,birth_weight,mother_adult_weight,father_adult_weight,predicted_weight,satisfaction_rating,satisfaction_rated_at",
    "order": "prediction_started_at.desc"
}

try:
    data_response = requests.get(data_url, headers=data_headers, params=params)
    data_response.raise_for_status()
    data = data_response.json()
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {len(data)}ä»¶")
except Exception as e:
    print(f"âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    exit()

# ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ãªã„ã‹ãƒã‚§ãƒƒã‚¯
if not data:
    print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    exit()

# DataFrameã«å¤‰æ›ã—ã€åˆ—åã‚’æ—¥æœ¬èªã«å¤‰æ›´
df = pd.DataFrame(data)

# åˆ—åã‚’æ—¥æœ¬èªã«å¤‰æ›´
column_mapping = {
    "id": "ID",
    "prediction_started_at": "äºˆæ¸¬é–‹å§‹æ™‚åˆ»",
    "prediction_completed_at": "äºˆæ¸¬å®Œäº†æ™‚åˆ»", 
    "line_user_id": "LINEãƒ¦ãƒ¼ã‚¶ãƒ¼ID",
    "display_name": "è¡¨ç¤ºå",
    "purchase_source": "è³¼å…¥å…ƒ",
    "has_purchase_experience": "è³¼å…¥çµŒé¨“",
    "breed": "çŠ¬ç¨®",
    "gender": "æ€§åˆ¥",
    "birth_date": "ç”Ÿå¹´æœˆæ—¥",
    "current_weight": "ç¾åœ¨ã®ä½“é‡(kg)",
    "birth_weight": "å‡ºç”Ÿæ™‚ä½“é‡(kg)",
    "mother_adult_weight": "æ¯çŠ¬æˆçŠ¬æ™‚ä½“é‡(kg)",
    "father_adult_weight": "çˆ¶çŠ¬æˆçŠ¬æ™‚ä½“é‡(kg)",
    "predicted_weight": "äºˆæ¸¬ä½“é‡(kg)",
    "satisfaction_rating": "æº€è¶³åº¦è©•ä¾¡",
    "satisfaction_rated_at": "æº€è¶³åº¦è©•ä¾¡æ™‚åˆ»"
}

df = df.rename(columns=column_mapping)

# ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
# æ™‚åˆ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®èª¿æ•´ï¼ˆæ—¥æœ¬æ™‚é–“ã«å¤‰æ›ï¼‰
time_columns = ["äºˆæ¸¬é–‹å§‹æ™‚åˆ»", "äºˆæ¸¬å®Œäº†æ™‚åˆ»", "æº€è¶³åº¦è©•ä¾¡æ™‚åˆ»"]
for col in time_columns:
    if col in df.columns and not df[col].isna().all():
        # æ™‚åˆ»ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
        datetime_series = pd.to_datetime(df[col])
        if datetime_series.dt.tz is None:
            # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ãŒãªã„å ´åˆã¯UTCã¨ã—ã¦æ‰±ã„æ—¥æœ¬æ™‚é–“ã«å¤‰æ›
            df[col] = datetime_series.dt.tz_localize('UTC').dt.tz_convert('Asia/Tokyo')
        else:
            # æ—¢ã«ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯æ—¥æœ¬æ™‚é–“ã«å¤‰æ›
            df[col] = datetime_series.dt.tz_convert('Asia/Tokyo')

# æº€è¶³åº¦è©•ä¾¡ã®æ—¥æœ¬èªåŒ–
if "æº€è¶³åº¦è©•ä¾¡" in df.columns:
    df["æº€è¶³åº¦è©•ä¾¡"] = df["æº€è¶³åº¦è©•ä¾¡"].map({"yes": "ã¯ã„", "no": "ã„ã„ãˆ"})

# è³¼å…¥çµŒé¨“ã®æ—¥æœ¬èªåŒ–
if "è³¼å…¥çµŒé¨“" in df.columns:
    df["è³¼å…¥çµŒé¨“"] = df["è³¼å…¥çµŒé¨“"].map({"yes": "ã¯ã„", "no": "ã„ã„ãˆ"})

# æ€§åˆ¥ã®æ—¥æœ¬èªåŒ–
if "æ€§åˆ¥" in df.columns:
    df["æ€§åˆ¥"] = df["æ€§åˆ¥"].map({"male": "ã‚ªã‚¹", "female": "ãƒ¡ã‚¹"})

# è³¼å…¥å…ƒã®æ—¥æœ¬èªåŒ–
if "è³¼å…¥å…ƒ" in df.columns:
    df["è³¼å…¥å…ƒ"] = df["è³¼å…¥å…ƒ"].map({"petshop": "ãƒšãƒƒãƒˆã‚·ãƒ§ãƒƒãƒ—", "breeder": "ãƒ–ãƒªãƒ¼ãƒ€ãƒ¼", "other": "ãã®ä»–"})

# FLUX.1ã«ã‚ˆã‚‹ç”»åƒç”Ÿæˆæ©Ÿèƒ½
def generate_dog_image(breed, gender, predicted_weight):
    """çŠ¬ã®å“ç¨®ã€æ€§åˆ¥ã€äºˆæ¸¬ä½“é‡ã‹ã‚‰ç”»åƒã‚’ç”Ÿæˆ"""
    
    # æ€§åˆ¥ã®è‹±èªå¤‰æ›
    gender_en = "male" if gender == "ã‚ªã‚¹" else "female"
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆï¼ˆäººã¨ä¸€ç·’ã§ã‚µã‚¤ã‚ºæ„ŸãŒã‚ã‹ã‚‹ã‚ˆã†ã«ï¼‰
    prompt = f"A realistic photo of an adult {gender_en} {breed} dog weighing approximately {predicted_weight}kg standing next to a person for size comparison, full body shot, high quality, professional photography"
    
    headers = {
        "Authorization": f"Token {REPLICATE_API_TOKEN}",
        "Content-Type": "application/json"
    }
    
    data = {
        "version": "black-forest-labs/flux-1.1-pro",
        "input": {
            "prompt": prompt,
            "width": 1024,
            "height": 768,
            "num_outputs": 1,
            "guidance_scale": 3.5,
            "num_inference_steps": 28,
            "seed": None,
            "output_format": "png",
            "output_quality": 80
        }
    }
    
    try:
        # ç”»åƒç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        response = requests.post(
            "https://api.replicate.com/v1/predictions",
            headers=headers,
            json=data
        )
        response.raise_for_status()
        
        prediction = response.json()
        prediction_id = prediction["id"]
        
        # ç”Ÿæˆå®Œäº†ã¾ã§å¾…æ©Ÿ
        while True:
            status_response = requests.get(
                f"https://api.replicate.com/v1/predictions/{prediction_id}",
                headers=headers
            )
            status_response.raise_for_status()
            
            result = status_response.json()
            
            if result["status"] == "succeeded":
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
                print(f"ğŸ” APIå¿œç­”: {result}")
                output = result.get("output")
                if output and len(output) > 0:
                    return output[0]
                else:
                    print("âŒ å‡ºåŠ›ãŒç©ºã§ã™")
                    return None
            elif result["status"] == "failed":
                print(f"âŒ ç”»åƒç”Ÿæˆå¤±æ•—: {result.get('error', 'Unknown error')}")
                return None
            
            time.sleep(2)  # 2ç§’å¾…æ©Ÿ
            
    except Exception as e:
        print(f"âŒ ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# æˆçŠ¬æ™‚ã‚µã‚¤ã‚ºæ„ŸãŒã‚ã‹ã‚‹ç”»åƒã‚’1æšç”Ÿæˆï¼ˆæœ€åˆã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã¿ï¼‰
print("\nğŸ¨ æˆçŠ¬æ™‚ã‚µã‚¤ã‚ºæ„Ÿç”»åƒç”Ÿæˆ...")
df["ç”Ÿæˆç”»åƒURL"] = ""

# æœ€åˆã®æœ‰åŠ¹ãªãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã¿å‡¦ç†
for index, row in df.iterrows():
    if pd.notna(row["çŠ¬ç¨®"]) and pd.notna(row["æ€§åˆ¥"]) and pd.notna(row["äºˆæ¸¬ä½“é‡(kg)"]):
        print(f"ç”»åƒç”Ÿæˆä¸­: {row['çŠ¬ç¨®']} ({row['æ€§åˆ¥']}, {row['äºˆæ¸¬ä½“é‡(kg)']}kg)")
        
        image_url = generate_dog_image(
            breed=row["çŠ¬ç¨®"],
            gender=row["æ€§åˆ¥"], 
            predicted_weight=row["äºˆæ¸¬ä½“é‡(kg)"]
        )
        
        if image_url:
            df.at[index, "ç”Ÿæˆç”»åƒURL"] = image_url
            print(f"âœ… ç”Ÿæˆå®Œäº†: {image_url}")
            print(f"ğŸ–¼ï¸ æˆçŠ¬æ™‚ã‚µã‚¤ã‚ºæ„Ÿç”»åƒ: {image_url}")
            
            # ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä¿å­˜
            try:
                img_response = requests.get(image_url)
                img_response.raise_for_status()
                img_filename = f"dog_size_reference_{row['çŠ¬ç¨®']}_{predicted_weight}kg.png"
                with open(img_filename, 'wb') as f:
                    f.write(img_response.content)
                print(f"ğŸ’¾ ç”»åƒä¿å­˜å®Œäº†: {img_filename}")
                
                # ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦HTMLè¡¨ç¤ºç”¨ã«æº–å‚™
                import base64
                with open(img_filename, 'rb') as f:
                    img_data = base64.b64encode(f.read()).decode()
                
                # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¦ç”»åƒã‚’è¡¨ç¤º
                html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>æˆçŠ¬æ™‚ã‚µã‚¤ã‚ºæ„Ÿç”»åƒ</title>
    <style>
        body {{ font-family: Arial, sans-serif; text-align: center; padding: 20px; }}
        img {{ max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 8px; }}
        h1 {{ color: #333; }}
        p {{ color: #666; }}
    </style>
</head>
<body>
    <h1>æˆçŠ¬æ™‚ã‚µã‚¤ã‚ºæ„Ÿç”»åƒ</h1>
    <p>çŠ¬ç¨®: {row['çŠ¬ç¨®']} | æ€§åˆ¥: {row['æ€§åˆ¥']} | äºˆæ¸¬ä½“é‡: {predicted_weight}kg</p>
    <img src="data:image/png;base64,{img_data}" alt="çŠ¬ã®ã‚µã‚¤ã‚ºæ„Ÿç”»åƒ">
    <p>ç”»åƒURL: <a href="{image_url}" target="_blank">{image_url}</a></p>
</body>
</html>
"""
                
                html_filename = f"dog_image_display_{row['çŠ¬ç¨®']}.html"
                with open(html_filename, 'w', encoding='utf-8') as f:
                    f.write(html_content)
                print(f"ğŸŒ HTMLè¡¨ç¤ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {html_filename}")
                
            except Exception as e:
                print(f"âŒ ç”»åƒä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            print("âŒ ç”Ÿæˆå¤±æ•—")
        
        break  # 1æšã®ã¿ç”Ÿæˆ

print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:")
print(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df)}")
print(f"åˆ—æ•°: {len(df.columns)}")
print("\nğŸ“ åˆ—åä¸€è¦§:")
for i, col in enumerate(df.columns, 1):
    print(f"{i:2d}. {col}")

# CSVã¨ã—ã¦å‡ºåŠ›
output_filename = "pwds_prediction_logs.csv"
df.to_csv(output_filename, index=False, encoding='utf-8-sig')
print(f"\nâœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†: {output_filename}")

# ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
print("\nğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€æ–°5ä»¶ï¼‰:")
preview_df = df.head()
for col in preview_df.columns:
    if len(str(col)) > 15:
        preview_df = preview_df.rename(columns={col: col[:12] + "..."})

print(preview_df.to_string(index=False))

# Google Colabç’°å¢ƒã®å ´åˆã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
try:
    from google.colab import files
    files.download(output_filename)
    print(f"\nâ¬‡ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {output_filename}")
except ImportError:
    print(f"\nğŸ’¾ ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {output_filename}")